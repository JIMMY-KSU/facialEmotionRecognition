{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import glob\n",
    "import random\n",
    "import numpy as np\n",
    "import glob\n",
    "from scipy.ndimage import zoom\n",
    "\n",
    "emotions = [\"neutral\", \"anger\", \"contempt\", \"disgust\", \"fear\", \"happy\", \"sadness\", \"surprise\"] #Emotion list\n",
    "fishface = cv2.face.createFisherFaceRecognizer() #Initialize fisher face classifier\n",
    "\n",
    "# ------------------- LIVE FACE RECOGNITION -----------------------------------\n",
    "def detectFaces(frame):\n",
    "    '''cascPath = \"haarcascade_frontalface_default.xml\"\n",
    "    faceCascade = cv2.CascadeClassifier(cascPath)\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    detected_faces = faceCascade.detectMultiScale(\n",
    "            gray,\n",
    "            scaleFactor=1.1,\n",
    "            minNeighbors=6,\n",
    "            minSize=(50, 50),\n",
    "            flags=cv2.CASCADE_SCALE_IMAGE)'''\n",
    "    faceDet = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
    "    faceDet2 = cv2.CascadeClassifier(\"haarcascade_frontalface_alt2.xml\")\n",
    "    faceDet3 = cv2.CascadeClassifier(\"haarcascade_frontalface_alt.xml\")\n",
    "    faceDet4 = cv2.CascadeClassifier(\"haarcascade_frontalface_alt_tree.xml\")\n",
    "    \n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) #Convert image to grayscale\n",
    "\n",
    "    #Detect face using 4 different classifiers\n",
    "    face = faceDet.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=10, minSize=(5, 5), flags=cv2.CASCADE_SCALE_IMAGE)\n",
    "    face2 = faceDet2.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=10, minSize=(5, 5), flags=cv2.CASCADE_SCALE_IMAGE)\n",
    "    face3 = faceDet3.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=10, minSize=(5, 5), flags=cv2.CASCADE_SCALE_IMAGE)\n",
    "    face4 = faceDet4.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=10, minSize=(5, 5), flags=cv2.CASCADE_SCALE_IMAGE)\n",
    "    \n",
    "    facefeatures = []\n",
    "    #Go over detected faces, stop at first detected face, return empty if no face.\n",
    "    if len(face) == 1:\n",
    "        facefeatures = face\n",
    "    elif len(face2) == 1:\n",
    "        facefeatures == face2\n",
    "    elif len(face3) == 1:\n",
    "        facefeatures = face3\n",
    "    elif len(face4) == 1:\n",
    "        facefeatures = face4\n",
    "\n",
    "    #Cut and save face\n",
    "    '''for (x, y, w, h) in facefeatures: #get coordinates and size of rectangle containing face\n",
    "        gray = gray[y:y+h, x:x+w] #Cut the frame to size\n",
    "        detected_faces = fishface.detectMultiScale(\n",
    "            gray,\n",
    "            scaleFactor=1.1,\n",
    "            minNeighbors=6,\n",
    "            minSize=(50, 50),\n",
    "            flags=cv2.CASCADE_SCALE_IMAGE)'''\n",
    "        #out = cv2.resize(gray, (350, 350)) #Resize face so all images have same size\n",
    "  \n",
    "    return gray, facefeatures\n",
    "\n",
    "\n",
    "def extract_face_features(gray, detected_face, offset_coefficients):\n",
    "    (x, y, w, h) = detected_face\n",
    "    horizontal_offset = int(offset_coefficients[0] * w)\n",
    "    vertical_offset = int(offset_coefficients[1] * h)\n",
    "    extracted_face = gray[y + vertical_offset:y + h,\n",
    "                     x + horizontal_offset:x - horizontal_offset + w]\n",
    "    new_extracted_face = zoom(extracted_face, (350. / extracted_face.shape[0],\n",
    "                                               350. / extracted_face.shape[1]))\n",
    "    '''new_extracted_face = new_extracted_face.astype(np.float32)\n",
    "    new_extracted_face /= float(new_extracted_face.max())'''\n",
    "    return new_extracted_face\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    fishface.load(\"results_0.0.yml\")\n",
    "\n",
    "    video_capture = cv2.VideoCapture(0)\n",
    "\n",
    "    while True:\n",
    "        # Capture frame-by-frame\n",
    "        ret, frame = video_capture.read()\n",
    "\n",
    "        # detect faces\n",
    "        gray, detected_faces = detectFaces(frame)\n",
    "\n",
    "        face_index = 0\n",
    "\n",
    "        cv2.putText(frame, \"Press Esc to QUIT\", (15, 15), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,0), 1)\n",
    "        \n",
    "        # predict output\n",
    "        for face in detected_faces:\n",
    "            (x, y, w, h) = face\n",
    "            if w > 100:\n",
    "                # draw rectangle around face\n",
    "                cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "                \n",
    "                gray_temp = gray[y:y+h, x:x+w] #Cut the frame to size\n",
    "            \n",
    "                extracted_face = cv2.resize(gray_temp, (100, 100))\n",
    "                # extract features\n",
    "                #extracted_face = extract_face_features(gray, face, (0.075, 0.05)) #(0.075, 0.05)\n",
    "\n",
    "                # predict result\n",
    "                prediction_result = fishface.predict(extracted_face)\n",
    "\n",
    "                # draw extracted face in the top right corner\n",
    "                frame[face_index * 100: (face_index + 1) * 100, -101:-1, :] = cv2.cvtColor(extracted_face * 255, cv2.COLOR_GRAY2RGB)                \n",
    "\n",
    "                # annotate main image with a label\n",
    "                cv2.putText(frame, emotions[prediction_result],(x,y), cv2.FONT_HERSHEY_SCRIPT_SIMPLEX, 2, 155, 5)\n",
    "\n",
    "\n",
    "                # increment counter\n",
    "                face_index += 1\n",
    "\n",
    "        # Display the resulting frame\n",
    "        cv2.imshow('Video', frame)\n",
    "        if cv2.waitKey(10) & 0xFF == 27:\n",
    "            break\n",
    "\n",
    "    # When everything is done, release the capture\n",
    "    video_capture.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
